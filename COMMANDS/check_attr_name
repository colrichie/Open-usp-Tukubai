#!/usr/bin/env python
#coding: utf-8
#
# check_attr_name name 形式の属性チェック（Open usp Tukubai版）
# 
#designed by Nobuaki Tounaka
#written by Yoshio Katayama
#
#The MIT License
#
# Copyright (C) 2011 Universal Shell Programming Laboratory
#
#Permission is hereby granted, free of charge, to any person obtaining a copy
#of this software and associated documentation files (the "Software"), to deal
#in the Software without restriction, including without limitation the rights
#to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
#copies of the Software, and to permit persons to whom the Software is
#furnished to do so, subject to the following conditions:
#
#The above copyright notice and this permission notice shall be included in
#all copies or substantial portions of the Software.
#
#THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
#IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
#FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
#AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
#LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
#OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
#THE SOFTWARE.

from __future__ import print_function

_usage = "check_attr_name <check_file> <name_file>"
_option = "--through <string>"
_option1 = "--ngword <ng_file>"
_attribute = "n N (０以上整数)"
_attribute1 = "s S (符号つき整数)"
_attribute2 = "f F (小数)"
_attribute3 = "v V (符号つき小数)"
_attribute4 = "e E (英字)"
_attribute5 = "a A (アスキー文字)"
_attribute6 = "b B (英数字)"
_attribute7 = "h H (半角文字)"
_attribute8 = "z Z (全角文字)"
_attribute9 = "k K (全角カタカナ)"
_attribute10 = "x X (文字)"
_attribute11 = "c C (チェックディジット)"
_attribute12 = "o O (英大文字)"
_attribute13 = "j J (住所=全角+半角英数)"
_version = "Fri Oct 21 11:26:06 JST 2011"
_code = "Open usp Tukubai (LINUX+FREEBSD/PYTHON2.4/UTF-8)"
wide_class = ["W","F","A"]	# 全角文字クラス

import re
import os
import sys
import unicodedata

def error(msg, *arg):
	print('Error[check_attr_name] :', msg % arg, file=sys.stderr)
	sys.exit(1)

def usage():
	print("Usage    :", _usage, file=sys.stderr)
	print("Option   :", _option, file=sys.stderr)
	print("          ", _option1, file=sys.stderr)
	print("Attribute:", _attribute, file=sys.stderr)
	print("          ", _attribute1, file=sys.stderr)
	print("          ", _attribute2, file=sys.stderr)
	print("          ", _attribute3, file=sys.stderr)
	print("          ", _attribute4, file=sys.stderr)
	print("          ", _attribute5, file=sys.stderr)
	print("          ", _attribute6, file=sys.stderr)
	print("          ", _attribute7, file=sys.stderr)
	print("          ", _attribute8, file=sys.stderr)
	print("          ", _attribute9, file=sys.stderr)
	print("          ", _attribute10, file=sys.stderr)
	print("          ", _attribute11, file=sys.stderr)
	print("          ", _attribute12, file=sys.stderr)
	print("          ", _attribute13, file=sys.stderr)
	print("Version  :", _version, file=sys.stderr)
	print("          ", _code, file=sys.stderr)
	sys.exit(1)

#
# 入力ファイルオープン
#
def open_file(n, mode = 'r'):
	if type(n) == type(0):
		if n >= len(sys.argv):
			n = '-'
		else:
			n = sys.argv[n]
	if n == '-':
		file = sys.stdin
	else:
		try:
			file = open(n, mode)
		except:
			error("ファイル '%s' をオープンできません。", n)
	return file

#
# unicode 変換
#
def to_unicode(s):
	if sys.version_info >= (3, 0): return s
	try:
		return unicode(s, 'utf_8')
	except:
		error("不当なマルチバイト文字が含まれています。")

#
# 文字列にngword内の文字が含まれているか検査する
#
def checkNgword(s,ngword):
	if len(ngword)==0: return False	# ngwordの指定がなかったときはngword判定にはひっかからない
	# string2list()で変換された拡張文字列で検査する
	#  拡張文字は
	#   UCS2では文字列のlist(長さ2)のlist
	#   UCS4では文字列のlist
	#  いずれも先頭要素は標準文字
	for c in s:
		if isUCS2():
			cc=c[0]+c[1]	# 文字列のlistを連結して単一の文字列にする（各要素は代用対もありうる）
		else:
			cc=c
		for ng in ngword:	# ngは文字列
			if cc==ng:
				return True	# ngword判定でひっかかった
	return False	# 対象文字列にはngwordで指定された文字はみつからなかった

#
# 代用対前半部の判定
#
def isHighSurrogate(cp):
	if 0xd800 <= cp and cp <= 0xdbff: return True
	else:                             return False

#
# 代用対後半部の判定
#
def isLowSurrogate(cp):
	if 0xdc00 <= cp and cp <= 0xdfff: return True
	else:                             return False

#
# UCS2の判定
#
def isUCS2():
	if sys.maxunicode==0xFFFF: return True
	else:                      return False

#
# unicodedata.east_asian_width()「東アジアの文字幅」の修正版
#
def east_asian_width(c):
	if len(c)>=2: return unicodedata.east_asian_width(c)	# UCS2で代用対が与えられたとき
	# unicodedata.east_asian_width()は半角オーバ－ライン「‾」（U+203e）に対して
	# A（Ambiguous; 曖昧=ギリシャ文字/ロシア文字と同様に全角扱いされる）を返すので
	# Na（Narrow; 狭=半角英数記号）に準ずるものと修正する
	elif ord(c)==0x203e: return 'Na'
	else:                return unicodedata.east_asian_width(c)

#
# 拡張文字の標準文字部分について符号位置（code point）の取得
#
def xord(xchar):
	if len(xchar)>1:	# UCS2で代用対の場合 xcharは HighSurrogate+LowSurrogateの2文字分ある
		cp = 0x10000 + (ord(xchar[0]) - 0xD800) * 0x400 + (ord(xchar[1]) - 0xDC00);	# 代用対をdecodeする
	else:
		cp = ord(xchar)
	return cp

#
# 半角判定
#
def isHalfWidth(c):
	# 文字のEast_Asian_Width特性検査でFまたはWまたはAならば
	# F/W/A = Wide（全角英数記号） Full（漢字 ひらがな 全角カタカナ） Ambiguous（ロシア文字 ギリシャ文字）
	if east_asian_width(c) in wide_class: return False	# 全角
	else:                                 return True	# それ以外は半角

#
# 合成可能文字の判定
#
def isCombiningDiacriticalMark(cp):
	# unicodeにおける合成可能文字のブロック内か？
		#	0x3099 0x309a	仮名文字の合成可能濁点と合成可能半濁点
		#	0x0300-0x036F	ダイアクリティカルマーク（合成可能）
		#	0x1AB0-0x1AFF	ダイアクリティカルマーク（合成可能）拡張
		#	0x1DC0-0x1DFF	ダイアクリティカルマーク（合成可能）補助
		#	0x20D0-0x20FF	記号用ダイアクリティカルマーク（合成可能）
		#	0xFE20-0xFE2F	半記号（合成可能）
	if cp == 0x3099 or cp == 0x309a or \
		0x0300<=cp and cp <=0x036F or \
		0x1AB0<=cp and cp <=0x1AFF or \
		0x1DC0<=cp and cp <=0x1DFF or \
		0x20D0<=cp and cp <=0x20FF or \
		0xFE20<=cp and cp <=0xFE2F:
		return True
	else:	return False

#
# 異体字選択子（vaiation selector）の判定
#
def isVariationSelector(cp):
	# unicodeにおける異体字選択子のブロック内か？
		#	0xFE00-0xFE0F	Variation Selectors Supplement	字形選択子補助（SVS用）
		#	0xE0100-0xE01EF	Variation Selectors	字形選択子（IVS用）
	if  0xFE00<=cp  and cp <=0xFE0F or \
		0xE0100<=cp and cp <=0xE01EF:
		return True
	else:	return False

#
# 文字列の表示幅
#
def strwidth_u(s):
	wid = 0	# 表示幅の初期化
	# sは拡張文字列
	for xchar in s:
		if isHalfWidth(xchar[0]):	wid+=1	# 半角なら+1
		else:	wid+=2	# 全角なら+2
	return wid

#
# 文字列の分解
#
#	文字列を拡張文字の列に変換する	1文字が複数の符号位置であらわされている場合（代用対/結合文字/IVS/SVS）への対応
#		分解結果はリストとなり各要素（拡張文字）は
#			UCS2のときはリスト
#				[ 通常文字または文字列としての代用対 , 結合文字または異体字選択子（2バイトまたは代用対）または空文字 ]
#			UCS4のときは文字列
#				文字列（通常文字に結合文字または異体字選択子が付くことがある）
def string2list(s):
	StringList=[]
	if isUCS2():
		surrogate_pair=False	# UCS2では代用対（surrogate pair）がありうる
		prevchar=""
		for c in s:
			cp=ord(c)	# code point
			# 代用対（[D800～DBFF]+[DC00～DFFF]のペア）の存在を考慮する
			if not surrogate_pair:	# 代用対の処理中でなければ
				if isHighSurrogate(cp):	# 代用対の前半部なら
					surrogate_pair=True	# surrogate pair starts
					HighSurrogate=c
					HighSurrogateCp=cp
					continue
				if isLowSurrogate(cp):	error("代用対の構成が無効です。")	# 代用対の後半部が単独で現れた
				elif isCombiningDiacriticalMark(cp):	# 合成可能文字なら
					if prevchar=="":	error("結合文字列の構成が無効です。")	# 空文字の次に合成可能文字が現われた
					StringList.append([prevchar,c])	# 先行文字と合成可能文字の組を追加（合成可能文字は第0面のみにある）
					prevchar=""
				elif isVariationSelector(cp):	# 異体字選択子なら
					if prevchar=="":	error("異体字列の構成が無効です。")	# 空文字の次に異体字選択子が現われた
					StringList.append([prevchar,c])	# 先行文字とSVS用異体字選択子（2バイト）の組を追加
					prevchar=""
				else:	# 次となる普通の文字がきたら先行文字を単独で追加
					if prevchar!="":
						StringList.append([prevchar,""])	# 先行文字と空文字の組を追加
					prevchar=c	# 先行文字とする
			elif isLowSurrogate(cp):	# 代用対の処理中に代用対の後半部がきたら代用対の完成
				surrogate_pair=False	# surrogate pair ends
				sp=HighSurrogate+c	# 代用対を作る
				uni = 0x10000 + (HighSurrogateCp - 0xD800) * 0x400 + (cp - 0xDC00);	# 代用対をdecodeする
				if isVariationSelector(uni):	# 代用対が異体字選択子なら
					if prevchar=="":	error("異体字列の構成が無効です。")	# 空文字の次に異体字選択子が現われた
					StringList.append([prevchar,sp])	# 先行文字とIVS用異体字選択子（4バイト）の組を追加
					prevchar=""
				else:	# 先行文字があって次に文字としての代用対が来た
					if prevchar!="":
						StringList.append([prevchar,""])	# 先行文字と空文字の組を追加
					prevchar=sp	# 代用対を先行文字とする
			else:	error("代用対の構成が無効です。")	# 代用対の前半部の次に代用対後半部以外が現われた
		if surrogate_pair: 	error("代用対の構成が無効です。")	# 代用対の前半部で文字列の終端に達した
		if prevchar!="":
			StringList.append([prevchar,""])	# 最後の先行文字と空文字の組を追加
	else:	# UCS4
		prevchar=""
		for c in s:
			cp=ord(c)	# code point
			if isCombiningDiacriticalMark(cp):	# 合成可能文字なら
				if prevchar=="":	error("結合文字列の構成が無効です。")	# 空文字の次に合成可能文字が現われた
				StringList.append(prevchar+c)	# 先行文字と合成可能文字の列を追加
				prevchar=""
			elif isVariationSelector(cp):	# 異体字選択子なら
				if prevchar=="":	error("異体字列の構成が無効です。")	# 空文字の次に異体字選択子が現われた
				StringList.append(prevchar+c)	# 先行文字とIVS用異体字選択子（4バイト）の列を追加
				prevchar=""
			else:
				if prevchar!="":	StringList.append(prevchar)	# 次となる普通の文字がきたら先行文字を単独で追加
				prevchar=c	# 先行文字とする
		if prevchar!="":
			StringList.append(prevchar)	# 最後の先行文字を追加
	return StringList

#
# ngword ファイルの読み込み
#	ngword指定ファイルの入力各行から空白/改行で区切られた文字列のうち先頭文字列の先頭文字をとってつないだ文字列を返す
#
def read_ngword(fname):
	ngword = []	# 文字列のlist
	for line in open_file(fname):
		l = [ x for x in re.split('[ \n]+', line) if x ]
		if l:
			s=to_unicode(l[0])
			s=string2list(s)	# 拡張文字列に変換（sの要素はUCS2のとき文字列のlist(長さ2)でUCS4では文字列）
			if isUCS2():
				ngword.append(s[0][0]+s[0][1])	# 文字列のlistを連結して単一の文字列にして追加（各要素は代用対もありうる）
			else:
				ngword.append(s[0])	# 先頭文字を意味する文字列を追加
	return ngword

#
# <check_file>
#
def read_check(n):
	letters = 'nNsSfFvVeEaAbBhHzZkKxXcCoOjJ-_'
	funcs = [
		chk_uint, chk_int, chk_ufloat, chk_float,
		chk_alpha, chk_ascii, chk_alnum, chk_halfwid,
		chk_fullwid, chk_fullkata, chk_valid, chk_checkdig,
		chk_upper, chk_addr, None
	]
	attr = []
	for line in open_file(1):
		l = [ x for x in re.split('[ \n]+', line) if x ]
		if len(l) < 2:
			continue
		if not l[1][0] in letters:
			error("属性が正しくありません: '%s'", l[1])
		f = funcs[letters.index(l[1][0]) // 2]
		if f:
			if l[1][0].lower() == 'f' or l[1][0].lower() == 'v':
				r = re.match(r'(\d*)\.?(\d*)$', l[1][1:])
			else:
				r = re.match(r'(\d*)()$', l[1][1:])
			if not r:
				error("属性が正しくありません: '%s'", l[1])
			w1 = int(r.group(1) or 0)
			w2 = int(r.group(2) or 0)
			attr += [ (l[0], l[1], w1, w2, f) ]
	return attr

#
# 符号無し整数
#
def chk_uint(attr, w1, w2, ngword, data):
	if not re.match(r'\d+$', data):
		return True
	elif attr[0].isupper():
		return w1 and len(data) != w1
	else:
		return w1 and len(data) > w1

#
# 符号付き整数
#
def chk_int(attr, w1, w2, ngword, data):
	r = re.match(r'[+-]?(\d+)$', data)
	if not r:
		return True
	elif attr[0].isupper():
		return w1 and len(r.group(1)) != w1
	else:
		return w1 and len(r.group(1)) > w1

#
# 符号無し小数 fF
#
def chk_ufloat(attr, w1, w2, ngword, data):
	r = re.match(r'(\d*)\.?(\d*)$', data)
	if not r or not r.group(1) + r.group(2):
		return True
	elif attr[0].isupper():
		return w1 and len(r.group(1)) != w1 \
			or w2 and len(r.group(2)) != w2
	else:
		return w1 and len(r.group(1)) > w1 \
			or w2 and len(r.group(2)) > w2

#
# 符号付き小数 vV
#
def chk_float(attr, w1, w2, ngword, data):
	r = re.match(r'[+-]?(\d*)\.?(\d*)$', data)
	if not r or not r.group(1) + r.group(2):
		return True
	elif attr[0].isupper():
		return w1 and len(r.group(1)) != w1 \
			or w2 and len(r.group(2)) != w2
	else:
		return w1 and len(r.group(1)) > w1 \
			or w2 and len(r.group(2)) > w2

#
# 英字 eE
#
def chk_alpha(attr, w1, w2, ngword, data):
	if not re.match(r'[a-zA-Z]+$', data):
		return True
	elif attr[0].isupper():
		return w1 and len(data) != w1
	else:
		return w1 and len(data) > w1

#
# 印刷可能文字(ASCII) aA
#
def chk_ascii(attr, w1, w2, ngword, data):
	if not re.match(r'[\x21-\x7e]+$', data):
		return True
	elif attr[0].isupper():
		return w1 and len(data) != w1
	else:
		return w1 and len(data) > w1

#
# 英数字 bB
#
def chk_alnum(attr, w1, w2, ngword, data):
	if not re.match(r'[a-zA-Z0-9]+$', data):
		return True
	elif attr[0].isupper():
		return w1 and len(data) != w1
	else:
		return w1 and len(data) > w1

#
# 半角文字 hH
#
def chk_halfwid(attr, w1, w2, ngword, data):
	data = to_unicode(data)
	data=string2list(data)
	for xchar in data:
		if not isHalfWidth(xchar[0]): return True	# 全角文字が入っているのをみつけた
	if attr[0].isupper():
		return w1 and len(data) != w1
	else:
		return w1 and len(data) > w1

#
# 全角文字 zZ
#
def chk_fullwid(attr, w1, w2, ngword, data):
	data = to_unicode(data)
	data=string2list(data)
	if checkNgword(data,ngword): return True	# ngword検査
	for xchar in data:
		if isHalfWidth(xchar[0]): return True	# 半角文字が入っているのをみつけた
	if attr[0].isupper():
		return w1 and strwidth_u(data) != w1
	else:
		return w1 and strwidth_u(data) > w1

#
# 全角カタカナ kK
#
def chk_fullkata(attr, w1, w2, ngword, data):
	data = to_unicode(data)
	data=string2list(data)
	if checkNgword(data,ngword): return True	# ngword検査
	for xchar in data:
		if len(xchar[0])>1: return True	# 全角カタカナはunicodeの第0面にあるのでUCS2での代用対なら該当しない
		cp=ord(xchar[0])	# 拡張文字の標準文字部分について符号位置（code point）をとる
		if  0x30a0<=cp and cp<=0x30ff or \
			0x31f0<=cp and cp<=0x31ff or \
			0x3000<=cp and cp<=0x303f: continue
			#0x3099==cp or cp==0x309a: continue	# 結合文字はここにこない
			#	U+30A0-30FF	Katakana 	片仮名（U+30fb～U+30ffは記号）（U+30a0ダブルハイフン「゠」はJISX0213-2004では記述記号）
			#	U+31F0-31FF	Katakana Phonetic Extensions 	片仮名拡張（小書き片仮名）
			#	U+3000-303F	CJK Symbols and Punctuation 	CJKの記号及び句読点
			#	U+3099-309A	合成用濁点/合成用半濁点
		else:
			return True
	if attr[0].isupper():
		return w1 and strwidth_u(data) != w1
	else:
		return w1 and strwidth_u(data) > w1

#
# 有効文字	xX
#
def chk_valid(attr, w1, w2, ngword, data):
	data = to_unicode(data)
	data=string2list(data)
	for xchar in data:
		cp=xord(xchar[0])	# 拡張文字の標準文字部分について符号位置をとる
		if (0x0000<=cp and cp <=0x0020) or cp==0x007f:
			return True
	if checkNgword(data,ngword):
		return True
	if attr[0].isupper():
		return w1 and strwidth_u(data) != w1
	else:
		return w1 and strwidth_u(data) > w1

#
# チェックデジット cC
#
def chk_checkdig(attr, w1, w2, ngword, data):
	if not re.match(r'\d+$', data):
		return True
	chk = 0
	for x in data:
		chk += int(x)
	for i in range(1, len(data), 2):
		chk += 2 * int(data[i])
	return chk % 10 != 0

#
# 英大文字 oO
#
def chk_upper(attr, w1, w2, ngword, data):
	if not re.match(r'[\x21-\x60\x7b-\x7e]+$', data):
		return True
	data = to_unicode(data)
	data=string2list(data)
	if attr[0].isupper():
		return w1 and len(data) != w1
	else:
		return w1 and len(data) > w1

#
# 住所用文字（全角文字＋半角英数）jJ
#
def chk_addr(attr, w1, w2, ngword, data):
	data = to_unicode(data)
	if re.search(r'[\x00-\x20\x7f]', data):	# 制御文字ははねる
		return True
	data=string2list(data)
	if checkNgword(data,ngword): return True
	for xchar in data:
		cp=xord(xchar[0])	# 拡張文字の標準文字部分について符号位置をとる
		if isHalfWidth(xchar[0]):	# 半角文字が入っているのをみつけた
			if not re.match(r'[a-zA-Z0-9]+$', xchar[0]):	# 半角英数ではない
				return True
	if attr[0].isupper():
		return w1 and strwidth_u(data) != w1
	else:
		return w1 and strwidth_u(data) > w1

#
#メイン関数
#
if __name__ == '__main__':

	if len(sys.argv) <= 1 \
	 or sys.argv[1] == '--help' \
	 or sys.argv[1] == '--version':
		usage()

	#
	# オプション解析
	#
	through, ngword = [], []
	while len(sys.argv) > 1:
		if sys.argv[1] == '--through':
			if len(sys.argv) <= 2:
				error("--through オプションの引数がありません。")
			through += [ sys.argv[2] ]
			del sys.argv[1:3]
		elif re.match(r'--through=(.+)', sys.argv[1]):	# --through=ファイル名
			r = re.match(r'--through=(.+)', sys.argv[1])
			through += [ r.group(1) ]
			del sys.argv[1]
		elif sys.argv[1] == '--ngword':
			if len(sys.argv) <= 2:
				error("--ngword オプションの引数がありません。")
			ngword+=(read_ngword(sys.argv[2]))
			del sys.argv[1:3]
		elif re.match(r'--ngword=(.+)', sys.argv[1]):	# --ngword=ファイル名
			r = re.match(r'--ngword=(.+)', sys.argv[1])
			ngword+=(read_ngword(r.group(1)))
			del sys.argv[1]
		elif sys.argv[1][0] == '-' and len(sys.argv[1]) > 1:
			error("不明なオプション(%s)です。", sys.argv[1])
		else:
			break
	if not through:
		through = [ '_' ]

	if len(sys.argv) <= 1:
		usage()

	#
	# <check_file>
	#
	attr = read_check(1)

	#
	# メインループ
	#
	stat = 0
	for line in open_file(2):
		l = re.findall(r' *([^ \n]+) ?(.*)', line)
		if not l or not l[0][1] or l[0][1] in through:
			continue
		for x in attr:
			if re.match(x[0] + r'(_[+-]?\d+)?$', l[0][0]):
				if x[-1](x[1], x[2], x[3], ngword, l[0][1]):
					print('%s %s' % (l[0][0], x[1]))
					stat = 1
				break

	sys.exit(stat)
